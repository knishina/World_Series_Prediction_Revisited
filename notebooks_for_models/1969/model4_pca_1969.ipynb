{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: Try different models-- Part4.\n",
    "### PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP1: Read in dataset.  Remove data from 2016-2019.\n",
    "- data from 2016-2018 will be used to bs test the model.\n",
    "- data from 2019 will be used to predict the winners of the 2019 WS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>SVO</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St. Louis Cardinals</td>\n",
       "      <td>2019</td>\n",
       "      <td>1033</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>936</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>895</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>3896</td>\n",
       "      <td>56</td>\n",
       "      <td>1.29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>2019</td>\n",
       "      <td>1010</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>945</td>\n",
       "      <td>8538.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2846</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>925</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>4001</td>\n",
       "      <td>53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas City Royals</td>\n",
       "      <td>2019</td>\n",
       "      <td>990</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>4125</td>\n",
       "      <td>39</td>\n",
       "      <td>1.46</td>\n",
       "      <td>34</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2019</td>\n",
       "      <td>875</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8589.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2863</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1074</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>3929</td>\n",
       "      <td>67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tampa Bay Rays</td>\n",
       "      <td>2019</td>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>963</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2920</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>3985</td>\n",
       "      <td>59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   team  year     A   DP   E   G2  GS2     INN  PB    PO  \\\n",
       "0   St. Louis Cardinals  2019  1033  114  43  104  936  8313.0   3  2771   \n",
       "1  Arizona Diamondbacks  2019  1010   83  45  105  945  8538.0   2  2846   \n",
       "2    Kansas City Royals  2019   990  105  45  106  954  8421.0   6  2807   \n",
       "3        Houston Astros  2019   875   54  50  106  954  8589.0   6  2863   \n",
       "4        Tampa Bay Rays  2019   975   92  53  107  963  8760.0  11  2920   \n",
       "\n",
       "    ...     SHO   SO1  SV  SVO   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   ...       4   895  33   42  3896  56  1.29  21  0.538        0  \n",
       "1   ...       7   925  24   37  4001  53  1.28  35  0.505        0  \n",
       "2   ...       5   816  24   41  4125  39  1.46  34  0.368        0  \n",
       "3   ...       7  1074  27   42  3929  67  1.14  31  0.632        0  \n",
       "4   ...       6  1037  26   43  3985  59  1.16  40  0.551        0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data.\n",
    "team_data = pd.read_csv(\"../../Resources/clean_data_1969.csv\")\n",
    "del team_data[\"Unnamed: 0\"]\n",
    "team_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>SVO</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>2015</td>\n",
       "      <td>1639</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4381</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1309</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "      <td>6048</td>\n",
       "      <td>87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>1425</td>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13137.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4379</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>6036</td>\n",
       "      <td>95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>47</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2015</td>\n",
       "      <td>1599</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4404</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>6180</td>\n",
       "      <td>84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>98</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>2015</td>\n",
       "      <td>1537</td>\n",
       "      <td>148</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>1449</td>\n",
       "      <td>12852.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1232</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>6048</td>\n",
       "      <td>86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>2015</td>\n",
       "      <td>1427</td>\n",
       "      <td>139</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>12957.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4319</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1362</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "      <td>6073</td>\n",
       "      <td>93</td>\n",
       "      <td>1.27</td>\n",
       "      <td>52</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     team  year     A   DP   E   G2   GS2      INN  PB    PO  \\\n",
       "120  San Francisco Giants  2015  1639  136  72  162  1458  13143.0   6  4381   \n",
       "121  Washington Nationals  2015  1425  142  73  162  1458  13137.0  17  4379   \n",
       "122        Houston Astros  2015  1599  135  77  162  1458  13212.0  18  4404   \n",
       "123        Detroit Tigers  2015  1537  148  75  161  1449  12852.0   5  4284   \n",
       "124        Boston Red Sox  2015  1427  139  75  162  1458  12957.0  37  4319   \n",
       "\n",
       "      ...     SHO   SO1  SV  SVO   TBF   W  WHIP  WP   WPCT  winners  \n",
       "120   ...      11  1309  43   72  6048  87  1.21  40  0.537        0  \n",
       "121   ...      12  1476  46   60  6036  95  1.19  47  0.586        0  \n",
       "122   ...       8  1396  44   64  6180  84  1.29  98  0.519        0  \n",
       "123   ...       8  1232  47   66  6048  86  1.32  44  0.534        0  \n",
       "124   ...       5  1362  43   61  6073  93  1.27  52  0.574        0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove data from 2016 through 2019.\n",
    "team_data_new = team_data.loc[team_data[\"year\"] < 2016]\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266,)\n",
      "(1266, 59)\n",
      "['A', 'DP', 'E', 'G2', 'GS2', 'INN', 'PB', 'PO', 'TC', '2B', '3B', 'AB', 'AO', 'BB', 'CS', 'G', 'GDP', 'H', 'HBP', 'HR', 'IBB', 'NP_x', 'OBP', 'OPS_x', 'PA', 'R', 'RBI', 'SAC', 'SB', 'SF', 'SLG', 'SO', 'TB', 'XBH', 'BB1', 'BK', 'CG', 'ER', 'ERA', 'G1', 'GF', 'GS', 'H1', 'HB', 'HR1', 'IBB1', 'IP', 'L', 'OBP1', 'R1', 'SHO', 'SO1', 'SV', 'SVO', 'TBF', 'W', 'WHIP', 'WP', 'WPCT']\n"
     ]
    }
   ],
   "source": [
    "target = team_data_new[\"winners\"]\n",
    "features = team_data_new.drop({\"team\", \"year\", \"winners\"}, axis=1)\n",
    "feature_columns = list(features.columns)\n",
    "print (target.shape)\n",
    "print (features.shape)\n",
    "print (feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP2: Upsample and scale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>SVO</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>2015</td>\n",
       "      <td>1639</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4381</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1309</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "      <td>6048</td>\n",
       "      <td>87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>1425</td>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13137.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4379</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "      <td>6036</td>\n",
       "      <td>95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>47</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2015</td>\n",
       "      <td>1599</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4404</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>44</td>\n",
       "      <td>64</td>\n",
       "      <td>6180</td>\n",
       "      <td>84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>98</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>2015</td>\n",
       "      <td>1537</td>\n",
       "      <td>148</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>1449</td>\n",
       "      <td>12852.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1232</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>6048</td>\n",
       "      <td>86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>2015</td>\n",
       "      <td>1427</td>\n",
       "      <td>139</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>12957.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4319</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1362</td>\n",
       "      <td>43</td>\n",
       "      <td>61</td>\n",
       "      <td>6073</td>\n",
       "      <td>93</td>\n",
       "      <td>1.27</td>\n",
       "      <td>52</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   team  year     A   DP   E   G2   GS2      INN  PB    PO  \\\n",
       "0  San Francisco Giants  2015  1639  136  72  162  1458  13143.0   6  4381   \n",
       "1  Washington Nationals  2015  1425  142  73  162  1458  13137.0  17  4379   \n",
       "2        Houston Astros  2015  1599  135  77  162  1458  13212.0  18  4404   \n",
       "3        Detroit Tigers  2015  1537  148  75  161  1449  12852.0   5  4284   \n",
       "4        Boston Red Sox  2015  1427  139  75  162  1458  12957.0  37  4319   \n",
       "\n",
       "    ...     SHO   SO1  SV  SVO   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   ...      11  1309  43   72  6048  87  1.21  40  0.537        0  \n",
       "1   ...      12  1476  46   60  6036  95  1.19  47  0.586        0  \n",
       "2   ...       8  1396  44   64  6180  84  1.29  98  0.519        0  \n",
       "3   ...       8  1232  47   66  6048  86  1.32  44  0.534        0  \n",
       "4   ...       5  1362  43   61  6073  93  1.27  52  0.574        0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index.\n",
    "team_data_new = team_data_new.reset_index().drop({\"index\"}, axis=1)\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>TC</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>SVO</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1033</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>936</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>3847</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>895</td>\n",
       "      <td>33</td>\n",
       "      <td>42</td>\n",
       "      <td>3896</td>\n",
       "      <td>56</td>\n",
       "      <td>1.29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>945</td>\n",
       "      <td>8538.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2846</td>\n",
       "      <td>3901</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>925</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>4001</td>\n",
       "      <td>53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>3842</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>4125</td>\n",
       "      <td>39</td>\n",
       "      <td>1.46</td>\n",
       "      <td>34</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8589.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2863</td>\n",
       "      <td>3788</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1074</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>3929</td>\n",
       "      <td>67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>963</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2920</td>\n",
       "      <td>3948</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>3985</td>\n",
       "      <td>59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   DP   E   G2  GS2     INN  PB    PO    TC   2B   ...     SHO   SO1  \\\n",
       "0  1033  114  43  104  936  8313.0   3  2771  3847  157   ...       4   895   \n",
       "1  1010   83  45  105  945  8538.0   2  2846  3901  203   ...       7   925   \n",
       "2   990  105  45  106  954  8421.0   6  2807  3842  185   ...       5   816   \n",
       "3   875   54  50  106  954  8589.0   6  2863  3788  200   ...       7  1074   \n",
       "4   975   92  53  107  963  8760.0  11  2920  3948  195   ...       6  1037   \n",
       "\n",
       "   SV  SVO   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0  33   42  3896  56  1.29  21  0.538        0  \n",
       "1  24   37  4001  53  1.28  35  0.505        0  \n",
       "2  24   41  4125  39  1.46  34  0.368        0  \n",
       "3  27   42  3929  67  1.14  31  0.632        0  \n",
       "4  26   43  3985  59  1.16  40  0.551        0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove team and year.\n",
    "feature_columns_new = feature_columns + [\"winners\"]\n",
    "team_data_new = team_data[feature_columns_new]\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample for a more balanced dataset.\n",
    "def upsample(dataset, no_samples, no_components):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -dataset = dataset without team names and year.\n",
    "    -n_samples = number of minority_unsampled.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -X_train_scaled = scaled X train data.\n",
    "    -X_test_scaled = scaled X test data.\n",
    "    -y_train = y train data\n",
    "    -y_test = y test data\n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -dataset is taken in and split into minority and majority classes.\n",
    "    -dataset is then upsampled for the mainority class\n",
    "    -split the data into features and targets\n",
    "    -split data into train and test sets\n",
    "    -train and test sets were are scaled.\n",
    "    '''\n",
    "    \n",
    "    # separate majority and minority classes.\n",
    "    df_majority = dataset.loc[dataset[\"winners\"] == 0]\n",
    "    df_minority = dataset.loc[dataset[\"winners\"] == 1]\n",
    "\n",
    "    # upsample minority class.\n",
    "    df_minority_unsampled = resample(df_minority,\n",
    "                                    replace=True,\n",
    "                                    n_samples=no_samples,\n",
    "                                    random_state=123)\n",
    "\n",
    "    # combine majority class with upsampled minority class.\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_unsampled])\n",
    "\n",
    "    # separate features and target.\n",
    "    y = df_upsampled[\"winners\"]\n",
    "    X = df_upsampled[feature_columns]\n",
    "    \n",
    "    # split into train and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    # scale.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    \n",
    "    # PCA.\n",
    "    pca = PCA(n_components=no_components)\n",
    "    X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "    X_test_scaled = pca.fit_transform(X_test_scaled)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Do three different upsamplings and three different pca conditions.\n",
    "X_train_100_10, X_test_100_10, y_train_100_10, y_test_100_10 = upsample(team_data_new, 2234, 10)\n",
    "X_train_100_5, X_test_100_5, y_train_100_5, y_test_100_5 = upsample(team_data_new, 2234, 5)\n",
    "X_train_100_2, X_test_100_2, y_train_100_2, y_test_100_2 = upsample(team_data_new, 2234, 2)\n",
    "\n",
    "X_train_50_10, X_test_50_10, y_train_50_10, y_test_50_10 = upsample(team_data_new, 1117, 10)\n",
    "X_train_50_5, X_test_50_5, y_train_50_5, y_test_50_5 = upsample(team_data_new, 1117, 5)\n",
    "X_train_50_2, X_test_50_2, y_train_50_2, y_test_50_2 = upsample(team_data_new, 1117, 2)\n",
    "\n",
    "X_train_25_10, X_test_25_10, y_train_25_10, y_test_25_10 = upsample(team_data_new, 559, 10)\n",
    "X_train_25_5, X_test_25_5, y_train_25_5, y_test_25_5 = upsample(team_data_new, 559, 5)\n",
    "X_train_25_2, X_test_25_2, y_train_25_2, y_test_25_2 = upsample(team_data_new, 559, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -X_test = scaled X test data.\n",
    "    -y_train = y train data.\n",
    "    -y_test = y test data.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -classification report (has F1 score, precision and recall).\n",
    "    -grid = saved model for prediction. \n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -the scaled and split data is put through a grid search with logistic.\n",
    "    -the model is trained.\n",
    "    -a prediction is made.\n",
    "    -print out the classification report and give the model.\n",
    "    '''\n",
    "    \n",
    "    # fit the model.\n",
    "    model = LogisticRegression(solver=\"lbfgs\", max_iter= 2000)\n",
    "\n",
    "    # fit the model.\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict.\n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    print (classification_report(y_test, prediction, target_names=[\"0\", \"1\"]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.40      0.52       356\n",
      "           1       0.70      0.91      0.79       537\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       893\n",
      "   macro avg       0.72      0.66      0.66       893\n",
      "weighted avg       0.71      0.71      0.68       893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100_10 = logistic(X_train_100_10, X_test_100_10, y_train_100_10, y_test_100_10)\n",
    "model_100_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.38      0.49       356\n",
      "           1       0.68      0.89      0.77       537\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       893\n",
      "   macro avg       0.69      0.64      0.63       893\n",
      "weighted avg       0.69      0.69      0.66       893\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100_5 = logistic(X_train_100_5, X_test_100_5, y_train_100_5, y_test_100_5)\n",
    "model_100_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       356\n",
      "           1       0.60      1.00      0.75       537\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       893\n",
      "   macro avg       0.30      0.50      0.38       893\n",
      "weighted avg       0.36      0.60      0.45       893\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100_2 = logistic(X_train_100_2, X_test_100_2, y_train_100_2, y_test_100_2)\n",
    "model_100_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       337\n",
      "           1       0.66      0.63      0.64       277\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       614\n",
      "   macro avg       0.68      0.68      0.68       614\n",
      "weighted avg       0.68      0.69      0.68       614\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50_10 = logistic(X_train_50_10, X_test_50_10, y_train_50_10, y_test_50_10)\n",
    "model_50_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.70       337\n",
      "           1       0.63      0.62      0.62       277\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       614\n",
      "   macro avg       0.66      0.66      0.66       614\n",
      "weighted avg       0.66      0.66      0.66       614\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50_5 = logistic(X_train_50_5, X_test_50_5, y_train_50_5, y_test_50_5)\n",
    "model_50_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       341\n",
      "           1       0.49      0.27      0.35       133\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       474\n",
      "   macro avg       0.63      0.58      0.58       474\n",
      "weighted avg       0.68      0.72      0.69       474\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25_10 = logistic(X_train_25_10, X_test_25_10, y_train_25_10, y_test_25_10)\n",
    "model_25_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       341\n",
      "           1       0.53      0.25      0.34       133\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       474\n",
      "   macro avg       0.64      0.58      0.58       474\n",
      "weighted avg       0.69      0.73      0.69       474\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25_5 = logistic(X_train_25_5, X_test_25_5, y_train_25_5, y_test_25_5)\n",
    "model_25_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84       341\n",
      "           1       0.00      0.00      0.00       133\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       474\n",
      "   macro avg       0.36      0.50      0.42       474\n",
      "weighted avg       0.52      0.72      0.60       474\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25_2 = logistic(X_train_25_2, X_test_25_2, y_train_25_2, y_test_25_2)\n",
    "model_25_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model_100_10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_the_winner(model, year, team_data, X_train, no_components):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -model = the saved model.\n",
    "    -team_data = complete dataframe with all data.\n",
    "    -year = the year want to look at.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -printed prediction.\n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -data from year of interest is isolated.\n",
    "    -the data are scaled.\n",
    "    -the prediction is made.\n",
    "    -print out the resulting probability and the name of the team.\n",
    "    '''\n",
    "    \n",
    "    # grab the data.\n",
    "    team_data = team_data.loc[team_data[\"year\"] == year].reset_index()\n",
    "\n",
    "    # set features (no team, year, winners).\n",
    "    # set target (winners).\n",
    "    features = team_data[feature_columns]\n",
    "    \n",
    "    # scale.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    features = scaler.fit_transform(features)\n",
    "    \n",
    "    # PCA.\n",
    "    pca = PCA(n_components=no_components)\n",
    "    X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "    features = pca.fit_transform(features)\n",
    "    \n",
    "    # fit the model.\n",
    "    probabilities = model.predict_proba(features)\n",
    "\n",
    "    # convert predictions to datafram.e\n",
    "    WS_predictions = pd.DataFrame(probabilities[:,1])\n",
    "\n",
    "    # Sort the DataFrame (descending)\n",
    "    WS_predictions = WS_predictions.sort_values(0, ascending=False)\n",
    "\n",
    "    WS_predictions['Probability'] = WS_predictions[0]\n",
    "\n",
    "    # Print 50 highest probability HoF inductees from still eligible players\n",
    "    for i, row in WS_predictions.head(50).iterrows():\n",
    "       prob = ' '.join(('WS Probability =', str(row['Probability'])))\n",
    "       print('')\n",
    "       print(prob)\n",
    "       print(team_data.iloc[i,1:27][\"team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WS Probability = 0.9272240314866262\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.8927810007504795\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.8381038938247545\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.8122081698634879\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.809414606869765\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.8088840975475382\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.7894264243030185\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.7713235070011902\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.7394907056641064\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.7384199185192116\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.707337327075642\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.7041691071875685\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.665703509831637\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.6601720055425523\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.6600219726683564\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.6579504266488614\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.6450293088567737\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.6425618082255625\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.5995096350011699\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.581687750826949\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.5301263353343623\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.506899216743228\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.4856724529454406\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.46338828530646514\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.45766455000907386\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.44954892384146117\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.38605610755135983\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.38462385751931666\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.38328875295084053\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.3368585130819281\n",
      "Toronto Blue Jays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2018.\n",
    "predict_the_winner(model_100_10, 2018, team_data, X_train_100_10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WS Probability = 0.923536827814462\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.8896645892650562\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.8789195668449965\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.8382196323520272\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.8370378858995692\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.8047490496898623\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.7914346466299593\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.757342552747389\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.7469744170466323\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.7405004105254391\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.7383581822128383\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.7208648942158487\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.7012026170842736\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.6748134192734231\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.6390800511977722\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.6186604079421839\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.6138365035097701\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.6102464412721883\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.6050905770906649\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.6047079038449948\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.5946558790157057\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.573592046764479\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.4820897348839021\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.4689715673187316\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.46227836622993124\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.42327654872514525\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.40008348569533514\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.3973222254165842\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.2476983551106846\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.2248121762250979\n",
      "Minnesota Twins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2017.\n",
    "predict_the_winner(model_100_10, 2017, team_data, X_train_100_10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is not it.  The F1 scores are terrible and the bs test doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
