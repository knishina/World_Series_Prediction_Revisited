{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: Try different models-- Part3.\n",
    "### Grid search with upsampling and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP1: Read in dataset.  Remove data from 2016-2019.\n",
    "- data from 2016-2018 will be used to bs test the model.\n",
    "- data from 2019 will be used to predict the winners of the 2019 WS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St. Louis Cardinals</td>\n",
       "      <td>2019</td>\n",
       "      <td>1033</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>936</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>4</td>\n",
       "      <td>895</td>\n",
       "      <td>33</td>\n",
       "      <td>3896</td>\n",
       "      <td>56</td>\n",
       "      <td>1.29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>2019</td>\n",
       "      <td>1010</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>945</td>\n",
       "      <td>8538.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2846</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>7</td>\n",
       "      <td>925</td>\n",
       "      <td>24</td>\n",
       "      <td>4001</td>\n",
       "      <td>53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas City Royals</td>\n",
       "      <td>2019</td>\n",
       "      <td>990</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>...</td>\n",
       "      <td>543</td>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>24</td>\n",
       "      <td>4125</td>\n",
       "      <td>39</td>\n",
       "      <td>1.46</td>\n",
       "      <td>34</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2019</td>\n",
       "      <td>875</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8589.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2863</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>7</td>\n",
       "      <td>1074</td>\n",
       "      <td>27</td>\n",
       "      <td>3929</td>\n",
       "      <td>67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tampa Bay Rays</td>\n",
       "      <td>2019</td>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>963</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2920</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>26</td>\n",
       "      <td>3985</td>\n",
       "      <td>59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   team  year     A   DP   E   G2  GS2     INN  PB    PO  \\\n",
       "0   St. Louis Cardinals  2019  1033  114  43  104  936  8313.0   3  2771   \n",
       "1  Arizona Diamondbacks  2019  1010   83  45  105  945  8538.0   2  2846   \n",
       "2    Kansas City Royals  2019   990  105  45  106  954  8421.0   6  2807   \n",
       "3        Houston Astros  2019   875   54  50  106  954  8589.0   6  2863   \n",
       "4        Tampa Bay Rays  2019   975   92  53  107  963  8760.0  11  2920   \n",
       "\n",
       "    ...      R1  SHO   SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   ...     456    4   895  33  3896  56  1.29  21  0.538        0  \n",
       "1   ...     472    7   925  24  4001  53  1.28  35  0.505        0  \n",
       "2   ...     543    5   816  24  4125  39  1.46  34  0.368        0  \n",
       "3   ...     432    7  1074  27  3929  67  1.14  31  0.632        0  \n",
       "4   ...     409    6  1037  26  3985  59  1.16  40  0.551        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data.\n",
    "team_data = pd.read_csv(\"../../Resources/clean_data_1905.csv\")\n",
    "del team_data[\"Unnamed: 0\"]\n",
    "team_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>2015</td>\n",
       "      <td>1639</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4381</td>\n",
       "      <td>...</td>\n",
       "      <td>631</td>\n",
       "      <td>11</td>\n",
       "      <td>1309</td>\n",
       "      <td>43</td>\n",
       "      <td>6048</td>\n",
       "      <td>87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>1425</td>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13137.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4379</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>46</td>\n",
       "      <td>6036</td>\n",
       "      <td>95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>47</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2015</td>\n",
       "      <td>1599</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4404</td>\n",
       "      <td>...</td>\n",
       "      <td>701</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>44</td>\n",
       "      <td>6180</td>\n",
       "      <td>84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>98</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>2015</td>\n",
       "      <td>1537</td>\n",
       "      <td>148</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>1449</td>\n",
       "      <td>12852.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>721</td>\n",
       "      <td>8</td>\n",
       "      <td>1232</td>\n",
       "      <td>47</td>\n",
       "      <td>6048</td>\n",
       "      <td>86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>2015</td>\n",
       "      <td>1427</td>\n",
       "      <td>139</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>12957.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4319</td>\n",
       "      <td>...</td>\n",
       "      <td>694</td>\n",
       "      <td>5</td>\n",
       "      <td>1362</td>\n",
       "      <td>43</td>\n",
       "      <td>6073</td>\n",
       "      <td>93</td>\n",
       "      <td>1.27</td>\n",
       "      <td>52</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     team  year     A   DP   E   G2   GS2      INN  PB    PO  \\\n",
       "120  San Francisco Giants  2015  1639  136  72  162  1458  13143.0   6  4381   \n",
       "121  Washington Nationals  2015  1425  142  73  162  1458  13137.0  17  4379   \n",
       "122        Houston Astros  2015  1599  135  77  162  1458  13212.0  18  4404   \n",
       "123        Detroit Tigers  2015  1537  148  75  161  1449  12852.0   5  4284   \n",
       "124        Boston Red Sox  2015  1427  139  75  162  1458  12957.0  37  4319   \n",
       "\n",
       "      ...      R1  SHO   SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "120   ...     631   11  1309  43  6048  87  1.21  40  0.537        0  \n",
       "121   ...     612   12  1476  46  6036  95  1.19  47  0.586        0  \n",
       "122   ...     701    8  1396  44  6180  84  1.29  98  0.519        0  \n",
       "123   ...     721    8  1232  47  6048  86  1.32  44  0.534        0  \n",
       "124   ...     694    5  1362  43  6073  93  1.27  52  0.574        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove data from 2016 through 2019.\n",
    "team_data_new = team_data.loc[team_data[\"year\"] < 2016]\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2344,)\n",
      "(2344, 52)\n",
      "['A', 'DP', 'E', 'G2', 'GS2', 'INN', 'PB', 'PO', 'TC', '2B', '3B', 'AB', 'AO', 'BB', 'G', 'H', 'HBP', 'HR', 'NP_x', 'OBP', 'OPS_x', 'PA', 'R', 'RBI', 'SAC', 'SB', 'SLG', 'TB', 'XBH', 'BB1', 'BK', 'CG', 'ER', 'ERA', 'G1', 'GF', 'GS', 'H1', 'HB', 'HR1', 'IP', 'L', 'OBP1', 'R1', 'SHO', 'SO1', 'SV', 'TBF', 'W', 'WHIP', 'WP', 'WPCT']\n"
     ]
    }
   ],
   "source": [
    "target = team_data_new[\"winners\"]\n",
    "features = team_data_new.drop({\"team\", \"year\", \"winners\"}, axis=1)\n",
    "feature_columns = list(features.columns)\n",
    "print (target.shape)\n",
    "print (features.shape)\n",
    "print (feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP2: Upsample and scale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>2015</td>\n",
       "      <td>1639</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4381</td>\n",
       "      <td>...</td>\n",
       "      <td>631</td>\n",
       "      <td>11</td>\n",
       "      <td>1309</td>\n",
       "      <td>43</td>\n",
       "      <td>6048</td>\n",
       "      <td>87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>1425</td>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13137.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4379</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>46</td>\n",
       "      <td>6036</td>\n",
       "      <td>95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>47</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2015</td>\n",
       "      <td>1599</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4404</td>\n",
       "      <td>...</td>\n",
       "      <td>701</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>44</td>\n",
       "      <td>6180</td>\n",
       "      <td>84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>98</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>2015</td>\n",
       "      <td>1537</td>\n",
       "      <td>148</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>1449</td>\n",
       "      <td>12852.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>721</td>\n",
       "      <td>8</td>\n",
       "      <td>1232</td>\n",
       "      <td>47</td>\n",
       "      <td>6048</td>\n",
       "      <td>86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>2015</td>\n",
       "      <td>1427</td>\n",
       "      <td>139</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>12957.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4319</td>\n",
       "      <td>...</td>\n",
       "      <td>694</td>\n",
       "      <td>5</td>\n",
       "      <td>1362</td>\n",
       "      <td>43</td>\n",
       "      <td>6073</td>\n",
       "      <td>93</td>\n",
       "      <td>1.27</td>\n",
       "      <td>52</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   team  year     A   DP   E   G2   GS2      INN  PB    PO  \\\n",
       "0  San Francisco Giants  2015  1639  136  72  162  1458  13143.0   6  4381   \n",
       "1  Washington Nationals  2015  1425  142  73  162  1458  13137.0  17  4379   \n",
       "2        Houston Astros  2015  1599  135  77  162  1458  13212.0  18  4404   \n",
       "3        Detroit Tigers  2015  1537  148  75  161  1449  12852.0   5  4284   \n",
       "4        Boston Red Sox  2015  1427  139  75  162  1458  12957.0  37  4319   \n",
       "\n",
       "    ...      R1  SHO   SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   ...     631   11  1309  43  6048  87  1.21  40  0.537        0  \n",
       "1   ...     612   12  1476  46  6036  95  1.19  47  0.586        0  \n",
       "2   ...     701    8  1396  44  6180  84  1.29  98  0.519        0  \n",
       "3   ...     721    8  1232  47  6048  86  1.32  44  0.534        0  \n",
       "4   ...     694    5  1362  43  6073  93  1.27  52  0.574        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index.\n",
    "team_data_new = team_data_new.reset_index().drop({\"index\"}, axis=1)\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>TC</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1033</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>936</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>3847</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>4</td>\n",
       "      <td>895</td>\n",
       "      <td>33</td>\n",
       "      <td>3896</td>\n",
       "      <td>56</td>\n",
       "      <td>1.29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>945</td>\n",
       "      <td>8538.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2846</td>\n",
       "      <td>3901</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>7</td>\n",
       "      <td>925</td>\n",
       "      <td>24</td>\n",
       "      <td>4001</td>\n",
       "      <td>53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>3842</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>543</td>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>24</td>\n",
       "      <td>4125</td>\n",
       "      <td>39</td>\n",
       "      <td>1.46</td>\n",
       "      <td>34</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8589.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2863</td>\n",
       "      <td>3788</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>7</td>\n",
       "      <td>1074</td>\n",
       "      <td>27</td>\n",
       "      <td>3929</td>\n",
       "      <td>67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>963</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2920</td>\n",
       "      <td>3948</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>26</td>\n",
       "      <td>3985</td>\n",
       "      <td>59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   DP   E   G2  GS2     INN  PB    PO    TC   2B   ...      R1  SHO  \\\n",
       "0  1033  114  43  104  936  8313.0   3  2771  3847  157   ...     456    4   \n",
       "1  1010   83  45  105  945  8538.0   2  2846  3901  203   ...     472    7   \n",
       "2   990  105  45  106  954  8421.0   6  2807  3842  185   ...     543    5   \n",
       "3   875   54  50  106  954  8589.0   6  2863  3788  200   ...     432    7   \n",
       "4   975   92  53  107  963  8760.0  11  2920  3948  195   ...     409    6   \n",
       "\n",
       "    SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   895  33  3896  56  1.29  21  0.538        0  \n",
       "1   925  24  4001  53  1.28  35  0.505        0  \n",
       "2   816  24  4125  39  1.46  34  0.368        0  \n",
       "3  1074  27  3929  67  1.14  31  0.632        0  \n",
       "4  1037  26  3985  59  1.16  40  0.551        0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove team and year.\n",
    "feature_columns_new = feature_columns + [\"winners\"]\n",
    "team_data_new = team_data[feature_columns_new]\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample for a more balanced dataset.\n",
    "def upsample(dataset, no_samples):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -dataset = dataset without team names and year.\n",
    "    -n_samples = number of minority_unsampled.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -X_train_scaled = scaled X train data.\n",
    "    -X_test_scaled = scaled X test data.\n",
    "    -y_train = y train data\n",
    "    -y_test = y test data\n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -dataset is taken in and split into minority and majority classes.\n",
    "    -dataset is then upsampled for the mainority class\n",
    "    -split the data into features and targets\n",
    "    -split data into train and test sets\n",
    "    -train and test sets were are scaled.\n",
    "    '''\n",
    "    \n",
    "    # separate majority and minority classes.\n",
    "    df_majority = dataset.loc[dataset[\"winners\"] == 0]\n",
    "    df_minority = dataset.loc[dataset[\"winners\"] == 1]\n",
    "\n",
    "    # upsample minority class.\n",
    "    df_minority_unsampled = resample(df_minority,\n",
    "                                    replace=True,\n",
    "                                    n_samples=no_samples,\n",
    "                                    random_state=123)\n",
    "\n",
    "    # combine majority class with upsampled minority class.\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_unsampled])\n",
    "\n",
    "    # separate features and target.\n",
    "    y = df_upsampled[\"winners\"]\n",
    "    X = df_upsampled[feature_columns]\n",
    "    \n",
    "    # split into train and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    # scale X_train and X_test.\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # transform the training and testing data.\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Do three different upsamplings.\n",
    "X_train_100, X_test_100, y_train_100, y_test_100 = upsample(team_data_new, 2234)\n",
    "X_train_50, X_test_50, y_train_50, y_test_50 = upsample(team_data_new, 1117)\n",
    "X_train_25, X_test_25, y_train_25, y_test_25 = upsample(team_data_new, 559)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP3: Grid Search Model--Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_logistic(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -X_test = scaled X test data.\n",
    "    -y_train = y train data.\n",
    "    -y_test = y test data.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -classification report (has F1 score, precision and recall).\n",
    "    -grid = saved model for prediction. \n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -the scaled and split data is put through a grid search with logistic.\n",
    "    -the model is trained.\n",
    "    -a prediction is made.\n",
    "    -print out the classification report and give the model.\n",
    "    '''\n",
    "    \n",
    "    # fit the model.\n",
    "    model = LogisticRegression(max_iter= 2000)\n",
    "    \n",
    "    # create gridsearch estimator.\n",
    "    param_grid = {\"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                 \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}\n",
    "    grid = GridSearchCV(model, param_grid, verbose=3, cv=5)\n",
    "\n",
    "    # fit the model.\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # predict.\n",
    "    prediction = grid.predict(X_test)\n",
    "    \n",
    "    # print out the basic information about the grid search.\n",
    "    print (grid.best_params_)\n",
    "    print (grid.best_score_)\n",
    "    print (grid.best_estimator_)\n",
    "    \n",
    "    grid = grid.best_estimator_\n",
    "    predictions = grid.predict(X_test)\n",
    "    print (classification_report(y_test, prediction, target_names=[\"0\", \"1\"]))\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7151162790697675, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7311046511627907, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7456395348837209, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7122093023255814, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7317784256559767, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7151162790697675, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7311046511627907, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7456395348837209, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7122093023255814, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7317784256559767, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7078488372093024, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7267441860465116, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, solver=liblinear, score=0.748546511627907, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7107558139534884, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7259475218658892, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7151162790697675, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7311046511627907, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7456395348837209, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7122093023255814, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7317784256559767, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7151162790697675, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7311046511627907, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7456395348837209, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7122093023255814, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7317784256559767, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7281976744186046, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.751453488372093, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7558139534883721, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7165697674418605, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7274052478134111, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7281976744186046, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] .... C=0.01, solver=lbfgs, score=0.751453488372093, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7558139534883721, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7165697674418605, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7274052478134111, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7267441860465116, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.751453488372093, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7616279069767442, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7180232558139535, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7244897959183674, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7281976744186046, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ...... C=0.01, solver=sag, score=0.751453488372093, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7558139534883721, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7165697674418605, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7274052478134111, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7281976744186046, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] ..... C=0.01, solver=saga, score=0.751453488372093, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7558139534883721, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7165697674418605, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7274052478134111, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7252906976744186, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7383720930232558, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7543604651162791, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7238372093023255, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7405247813411079, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7252906976744186, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7383720930232558, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7543604651162791, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7238372093023255, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7405247813411079, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7252906976744186, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7383720930232558, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7543604651162791, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7223837209302325, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7405247813411079, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7252906976744186, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7383720930232558, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7543604651162791, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7238372093023255, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7405247813411079, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.1, solver=saga, score=0.7252906976744186, total=   0.2s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7383720930232558, total=   0.2s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7543604651162791, total=   0.2s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7238372093023255, total=   0.2s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7405247813411079, total=   0.2s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7572674418604651, total=   0.1s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] ................ C=1, solver=newton-cg, score=0.75, total=   0.1s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7747093023255814, total=   0.1s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7412790697674418, total=   0.1s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] ... C=1, solver=newton-cg, score=0.749271137026239, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7587209302325582, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] .................... C=1, solver=lbfgs, score=0.75, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7747093023255814, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7398255813953488, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ....... C=1, solver=lbfgs, score=0.749271137026239, total=   0.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7572674418604651, total=   0.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ................ C=1, solver=liblinear, score=0.75, total=   0.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7747093023255814, total=   0.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7412790697674418, total=   0.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ... C=1, solver=liblinear, score=0.749271137026239, total=   0.1s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7572674418604651, total=   0.5s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ...................... C=1, solver=sag, score=0.75, total=   0.5s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7747093023255814, total=   0.5s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7398255813953488, total=   0.5s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ......... C=1, solver=sag, score=0.749271137026239, total=   0.5s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7572674418604651, total=   0.9s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ..................... C=1, solver=saga, score=0.75, total=   0.9s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7747093023255814, total=   0.8s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7398255813953488, total=   0.9s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ........ C=1, solver=saga, score=0.749271137026239, total=   0.8s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7674418604651163, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7252906976744186, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7747093023255814, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7659883720930233, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7594752186588921, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7674418604651163, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7252906976744186, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7747093023255814, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7659883720930233, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7594752186588921, total=   0.2s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7674418604651163, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7252906976744186, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7747093023255814, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7659883720930233, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7594752186588921, total=   0.1s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7674418604651163, total=   2.5s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7267441860465116, total=   2.8s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7747093023255814, total=   2.6s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7659883720930233, total=   2.8s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7580174927113703, total=   2.7s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7674418604651163, total=   3.1s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7223837209302325, total=   3.2s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7718023255813954, total=   3.1s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7688953488372093, total=   3.1s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7594752186588921, total=   3.2s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7645348837209303, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7383720930232558, total=   0.2s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7776162790697675, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7659883720930233, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7696793002915452, total=   0.1s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7659883720930233, total=   0.4s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7383720930232558, total=   0.5s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7776162790697675, total=   0.5s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7659883720930233, total=   0.5s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7696793002915452, total=   0.5s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7659883720930233, total=   0.2s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7383720930232558, total=   0.2s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7776162790697675, total=   0.2s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7659883720930233, total=   0.2s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7711370262390671, total=   0.3s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7674418604651163, total=   3.0s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7340116279069767, total=   3.0s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7790697674418605, total=   3.0s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7645348837209303, total=   3.0s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=100, solver=sag, score=0.760932944606414, total=   3.0s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7587209302325582, total=   3.4s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7267441860465116, total=   4.2s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7761627906976745, total=   3.2s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7718023255813954, total=   3.1s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7623906705539358, total=   3.1s\n",
      "{'C': 100, 'solver': 'liblinear'}\n",
      "0.7638161721931356\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75       607\n",
      "           1       0.71      0.76      0.73       540\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1147\n",
      "   macro avg       0.74      0.74      0.74      1147\n",
      "weighted avg       0.74      0.74      0.74      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for 1 part 0 to 1 part 1\n",
    "model_100 = grid_search_logistic(X_train_100, X_test_100, y_train_100, y_test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.727447216890595, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7442307692307693, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.7096153846153846, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV] ........... C=0.001, solver=newton-cg, score=0.725, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] ... C=0.001, solver=lbfgs, score=0.727447216890595, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7442307692307693, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.7096153846153846, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] ............... C=0.001, solver=lbfgs, score=0.725, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7005758157389635, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7153846153846154, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7057692307692308, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, solver=liblinear, score=0.7153846153846154, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7153846153846154, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] ..... C=0.001, solver=sag, score=0.727447216890595, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7442307692307693, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.7096153846153846, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] ................. C=0.001, solver=sag, score=0.725, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] .... C=0.001, solver=saga, score=0.727447216890595, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7442307692307693, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.7096153846153846, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ................ C=0.001, solver=saga, score=0.725, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7351247600767754, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7596153846153846, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7634615384615384, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7211538461538461, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7351247600767754, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7596153846153846, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7634615384615384, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7211538461538461, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7216890595009597, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7673076923076924, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7326923076923076, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7211538461538461, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.7346153846153847, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7351247600767754, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7596153846153846, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7634615384615384, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7211538461538461, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7351247600767754, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7596153846153846, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7634615384615384, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7211538461538461, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7485604606525912, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7673076923076924, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7653846153846153, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7519230769230769, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7485604606525912, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7673076923076924, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7653846153846153, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7519230769230769, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.7423076923076923, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7504798464491362, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7711538461538462, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7653846153846153, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7480769230769231, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.7461538461538462, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7485604606525912, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7673076923076924, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7653846153846153, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7519230769230769, total=   0.1s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.7423076923076923, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7485604606525912, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7673076923076924, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.1, solver=saga, score=0.7653846153846153, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7519230769230769, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.7423076923076923, total=   0.1s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7485604606525912, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7788461538461539, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7673076923076924, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7576923076923077, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.7384615384615385, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7485604606525912, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7788461538461539, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7673076923076924, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7576923076923077, total=   0.1s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.7384615384615385, total=   0.1s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ... C=1, solver=liblinear, score=0.746641074856046, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7788461538461539, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7673076923076924, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7576923076923077, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.7384615384615385, total=   0.0s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7485604606525912, total=   0.4s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7788461538461539, total=   0.4s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7673076923076924, total=   0.4s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7576923076923077, total=   0.4s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.7384615384615385, total=   0.4s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7485604606525912, total=   0.6s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7788461538461539, total=   0.6s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7673076923076924, total=   0.6s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7576923076923077, total=   0.6s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.7384615384615385, total=   0.6s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7581573896353166, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7634615384615384, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7596153846153846, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7634615384615384, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.7230769230769231, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7581573896353166, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7634615384615384, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7596153846153846, total=   0.2s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7634615384615384, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.7230769230769231, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7581573896353166, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7634615384615384, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7596153846153846, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7634615384615384, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.7230769230769231, total=   0.1s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7581573896353166, total=   1.9s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7634615384615384, total=   1.9s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7596153846153846, total=   1.9s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7634615384615384, total=   1.9s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.7230769230769231, total=   1.9s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7581573896353166, total=   2.3s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7634615384615384, total=   2.3s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7596153846153846, total=   2.3s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.7576923076923077, total=   2.3s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, solver=saga, score=0.725, total=   2.3s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7485604606525912, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7673076923076924, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7557692307692307, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.7653846153846153, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV] ............. C=100, solver=newton-cg, score=0.725, total=   0.1s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7485604606525912, total=   0.3s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7673076923076924, total=   0.3s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7557692307692307, total=   0.3s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.7653846153846153, total=   0.3s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] ................. C=100, solver=lbfgs, score=0.725, total=   0.3s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7428023032629558, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7673076923076924, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7557692307692307, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7653846153846153, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.7269230769230769, total=   0.1s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7523992322456814, total=   2.2s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7711538461538462, total=   2.2s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7538461538461538, total=   2.3s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7653846153846153, total=   2.2s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.7269230769230769, total=   2.2s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7485604606525912, total=   2.3s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7634615384615384, total=   2.3s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7538461538461538, total=   2.3s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.7596153846153846, total=   2.3s\n",
      "[CV] C=100, solver=saga ..............................................\n",
      "[CV] ..... C=100, solver=saga, score=0.7269230769230769, total=   2.3s\n",
      "{'C': 1, 'solver': 'newton-cg'}\n",
      "0.7581699346405228\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='newton-cg',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       606\n",
      "           1       0.68      0.55      0.61       261\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       867\n",
      "   macro avg       0.75      0.72      0.73       867\n",
      "weighted avg       0.78      0.79      0.78       867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   55.8s finished\n"
     ]
    }
   ],
   "source": [
    "# for 1 part 0 to 0.5 part 1\n",
    "model_50 = grid_search_logistic(X_train_50, X_test_50, y_train_50, y_test_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.8100686498855835, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.8146453089244852, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=newton-cg .......................................\n",
      "[CV]  C=0.001, solver=newton-cg, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.8100686498855835, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.8146453089244852, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=lbfgs ...........................................\n",
      "[CV] .. C=0.001, solver=lbfgs, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.782608695652174, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7963386727688787, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7958715596330275, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.7614678899082569, total=   0.0s\n",
      "[CV] C=0.001, solver=liblinear .......................................\n",
      "[CV]  C=0.001, solver=liblinear, score=0.805045871559633, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.8100686498855835, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... C=0.001, solver=sag, score=0.8146453089244852, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=sag .............................................\n",
      "[CV] .... C=0.001, solver=sag, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.8100686498855835, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.8146453089244852, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.001, solver=saga ............................................\n",
      "[CV] ... C=0.001, solver=saga, score=0.8119266055045872, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.8192219679633868, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.8329519450800915, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=newton-cg ........................................\n",
      "[CV]  C=0.01, solver=newton-cg, score=0.823394495412844, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.8192219679633868, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.8329519450800915, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] ... C=0.01, solver=lbfgs, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=lbfgs ............................................\n",
      "[CV] .... C=0.01, solver=lbfgs, score=0.823394495412844, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.8146453089244852, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.851258581235698, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.8302752293577982, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.8188073394495413, total=   0.0s\n",
      "[CV] C=0.01, solver=liblinear ........................................\n",
      "[CV]  C=0.01, solver=liblinear, score=0.823394495412844, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.8192219679633868, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.8329519450800915, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ..... C=0.01, solver=sag, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=sag ..............................................\n",
      "[CV] ...... C=0.01, solver=sag, score=0.823394495412844, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.8192219679633868, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.8329519450800915, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] .... C=0.01, solver=saga, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.01, solver=saga .............................................\n",
      "[CV] ..... C=0.01, solver=saga, score=0.823394495412844, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV] . C=0.1, solver=newton-cg, score=0.816933638443936, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.8306636155606407, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.1, solver=newton-cg .........................................\n",
      "[CV]  C=0.1, solver=newton-cg, score=0.8211009174311926, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] ..... C=0.1, solver=lbfgs, score=0.816933638443936, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.8306636155606407, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.1, solver=lbfgs .............................................\n",
      "[CV] .... C=0.1, solver=lbfgs, score=0.8211009174311926, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV] . C=0.1, solver=liblinear, score=0.816933638443936, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.8306636155606407, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.8325688073394495, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.8302752293577982, total=   0.0s\n",
      "[CV] C=0.1, solver=liblinear .........................................\n",
      "[CV]  C=0.1, solver=liblinear, score=0.8211009174311926, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ....... C=0.1, solver=sag, score=0.816933638443936, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.8306636155606407, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=0.1, solver=sag ...............................................\n",
      "[CV] ...... C=0.1, solver=sag, score=0.8211009174311926, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ...... C=0.1, solver=saga, score=0.816933638443936, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.8306636155606407, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.8256880733944955, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n",
      "[CV] ..... C=0.1, solver=saga, score=0.8256880733944955, total=   0.1s\n",
      "[CV] C=0.1, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.1, solver=saga, score=0.8211009174311926, total=   0.1s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.8123569794050344, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.8398169336384439, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] ... C=1, solver=newton-cg, score=0.841743119266055, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.8279816513761468, total=   0.0s\n",
      "[CV] C=1, solver=newton-cg ...........................................\n",
      "[CV] .. C=1, solver=newton-cg, score=0.8211009174311926, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.8123569794050344, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.8398169336384439, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ....... C=1, solver=lbfgs, score=0.841743119266055, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.8279816513761468, total=   0.0s\n",
      "[CV] C=1, solver=lbfgs ...............................................\n",
      "[CV] ...... C=1, solver=lbfgs, score=0.8211009174311926, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.8123569794050344, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.8398169336384439, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] ... C=1, solver=liblinear, score=0.841743119266055, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.8279816513761468, total=   0.0s\n",
      "[CV] C=1, solver=liblinear ...........................................\n",
      "[CV] .. C=1, solver=liblinear, score=0.8211009174311926, total=   0.0s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.8123569794050344, total=   0.3s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.8398169336384439, total=   0.3s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ......... C=1, solver=sag, score=0.841743119266055, total=   0.3s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.8279816513761468, total=   0.3s\n",
      "[CV] C=1, solver=sag .................................................\n",
      "[CV] ........ C=1, solver=sag, score=0.8211009174311926, total=   0.3s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.8123569794050344, total=   0.5s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.8398169336384439, total=   0.5s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ........ C=1, solver=saga, score=0.841743119266055, total=   0.5s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.8279816513761468, total=   0.5s\n",
      "[CV] C=1, solver=saga ................................................\n",
      "[CV] ....... C=1, solver=saga, score=0.8211009174311926, total=   0.5s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.8123569794050344, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.8352402745995423, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.8394495412844036, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.8302752293577982, total=   0.1s\n",
      "[CV] C=10, solver=newton-cg ..........................................\n",
      "[CV] . C=10, solver=newton-cg, score=0.8256880733944955, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.8123569794050344, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.8352402745995423, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.8394495412844036, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.8302752293577982, total=   0.1s\n",
      "[CV] C=10, solver=lbfgs ..............................................\n",
      "[CV] ..... C=10, solver=lbfgs, score=0.8256880733944955, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.8123569794050344, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.8352402745995423, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.8394495412844036, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.8302752293577982, total=   0.1s\n",
      "[CV] C=10, solver=liblinear ..........................................\n",
      "[CV] . C=10, solver=liblinear, score=0.8256880733944955, total=   0.0s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.8123569794050344, total=   1.6s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.8352402745995423, total=   1.5s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ........ C=10, solver=sag, score=0.841743119266055, total=   1.6s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.8302752293577982, total=   1.6s\n",
      "[CV] C=10, solver=sag ................................................\n",
      "[CV] ....... C=10, solver=sag, score=0.8256880733944955, total=   1.5s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.8123569794050344, total=   1.9s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.8352402745995423, total=   1.9s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=10, solver=saga, score=0.841743119266055, total=   1.9s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.8302752293577982, total=   2.0s\n",
      "[CV] C=10, solver=saga ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=10, solver=saga, score=0.8256880733944955, total=   2.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.8100686498855835, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.8306636155606407, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.8371559633027523, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.8325688073394495, total=   0.1s\n",
      "[CV] C=100, solver=newton-cg .........................................\n",
      "[CV]  C=100, solver=newton-cg, score=0.8279816513761468, total=   0.1s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.8100686498855835, total=   0.3s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.8306636155606407, total=   0.2s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.8371559633027523, total=   0.3s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.8325688073394495, total=   0.2s\n",
      "[CV] C=100, solver=lbfgs .............................................\n",
      "[CV] .... C=100, solver=lbfgs, score=0.8279816513761468, total=   0.2s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.8100686498855835, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.8306636155606407, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.8371559633027523, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.8325688073394495, total=   0.1s\n",
      "[CV] C=100, solver=liblinear .........................................\n",
      "[CV]  C=100, solver=liblinear, score=0.8279816513761468, total=   0.1s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.8077803203661327, total=   2.1s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.8329519450800915, total=   2.0s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.8394495412844036, total=   1.9s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.8348623853211009, total=   1.9s\n",
      "[CV] C=100, solver=sag ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=100, solver=sag, score=0.8302752293577982, total=   1.8s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.8123569794050344, total=   1.9s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.8329519450800915, total=   1.9s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.8394495412844036, total=   1.9s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.8302752293577982, total=   1.9s\n",
      "[CV] C=100, solver=saga ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:   46.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=100, solver=saga, score=0.8279816513761468, total=   1.9s\n",
      "{'C': 10, 'solver': 'sag'}\n",
      "0.8290559120073328\n",
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89       579\n",
      "           1       0.60      0.27      0.37       149\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       728\n",
      "   macro avg       0.72      0.61      0.63       728\n",
      "weighted avg       0.79      0.81      0.78       728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for 1 part 0 to 0.25 part 1\n",
    "model_25 = grid_search_logistic(X_train_25, X_test_25, y_train_25, y_test_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not significantly better than the straight logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_the_winner(model, year, team_data, X_train):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -model = the saved model.\n",
    "    -team_data = complete dataframe with all data.\n",
    "    -year = the year want to look at.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -printed prediction.\n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -data from year of interest is isolated.\n",
    "    -the data are scaled.\n",
    "    -the prediction is made.\n",
    "    -print out the resulting probability and the name of the team.\n",
    "    '''\n",
    "    \n",
    "    # grab the data.\n",
    "    team_data = team_data.loc[team_data[\"year\"] == year].reset_index()\n",
    "\n",
    "    # set features (no team, year, winners).\n",
    "    # set target (winners).\n",
    "    features = team_data[feature_columns]\n",
    "    \n",
    "    # scale X_train and X_test.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    features = scaler.fit_transform(features)\n",
    "    \n",
    "    # fit the model.\n",
    "    probabilities = model.predict_proba(features)\n",
    "\n",
    "    # convert predictions to datafram.e\n",
    "    WS_predictions = pd.DataFrame(probabilities[:,1])\n",
    "\n",
    "    # Sort the DataFrame (descending)\n",
    "    WS_predictions = WS_predictions.sort_values(0, ascending=False)\n",
    "\n",
    "    WS_predictions['Probability'] = WS_predictions[0]\n",
    "\n",
    "    # Print 50 highest probability HoF inductees from still eligible players\n",
    "    for i, row in WS_predictions.head(50).iterrows():\n",
    "       prob = ' '.join(('WS Probability =', str(row['Probability'])))\n",
    "       print(prob)\n",
    "       print(team_data.iloc[i,1:27][\"team\"])\n",
    "       print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_100----------------------------------------\n",
      "WS Probability = 0.9999999507832171\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.9999995467046062\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.9999849646049372\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.9997809036939881\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.9995403353892793\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.9984988544849107\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.9949636755278962\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.9918219395658201\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.9872645944073091\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.9668929376606923\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.9259132305095067\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.9213012179329771\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.9108287526384264\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.8833878057060507\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.870908134526758\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.6128919875394272\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.3308201108001493\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.1488410858706063\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.1297674063072141\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.1158532650094888\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.017564394913776066\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.014875899088361493\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.00349342814378818\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.0033834428425664263\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.00017409880528557043\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.000160838129653538\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 2.474147271012328e-05\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 1.5679791800070307e-05\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 1.0898950873708287e-06\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 3.3470712106319117e-09\n",
      "San Francisco Giants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_100----------------------------------------\")\n",
    "predict_the_winner(model_100, 2018, team_data, X_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_50----------------------------------------\n",
      "WS Probability = 0.9873425039755489\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.9861004835313941\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.98251149010313\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.956312121432039\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.9518531682432401\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.9410812386375842\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.9195503403977436\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.8003720111678071\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.793528952833421\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.7468851288962158\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.6562118203440391\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.5604944547452536\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.5328698499518533\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.5000547117732359\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.20222927547548325\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.1507930820220956\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.0778761568158136\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.06554868701431861\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.06083137799013184\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.04919463562196923\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.047977086171793866\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.04282676142166491\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.03983372657705469\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.03278917382869801\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.022584090375643337\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.02065525643796977\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.009627147812365676\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.0038481836463385303\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.0012015847514093806\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.00029377823127953656\n",
      "Seattle Mariners\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_50----------------------------------------\")\n",
    "predict_the_winner(model_50, 2018, team_data, X_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_25----------------------------------------\n",
      "WS Probability = 0.9876767281504318\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.9085251512209893\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.864875289717516\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.8138905764966672\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.7506103267056896\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.733682737099985\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.7152819913798588\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.6910700294911415\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.6156636444549811\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.5649932751731225\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.5276434123265982\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.5216158086797604\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.4924571875768348\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.2849147194209658\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.2621025934423404\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.24101087499141857\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.07396391754580155\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.06486109937669214\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.045201688936407323\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.019726587441536787\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.0158404152990809\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.012454390361964097\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.0051434830471718505\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.004174930602362067\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.004017981679999072\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.0039873289810451315\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.002804896140000971\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.0022832435645562996\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.0007676734645303144\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 3.8111137828853168e-06\n",
      "Seattle Mariners\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_25----------------------------------------\")\n",
    "predict_the_winner(model_25, 2018, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precition for 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_100----------------------------------------\n",
      "WS Probability = 0.99999999882261\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.9999998928164447\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.9999998035062123\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.9999983643361261\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.999991743049209\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.9999746648151113\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.9998265050397431\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.9992274306742231\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.9991172424801942\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.9950263661475003\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.985268210190956\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.9783247010315036\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.9601963653017139\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.9127057752193434\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.8388795548874193\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.8283102858272211\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.7186036830742364\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.4719451836580121\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.11683039678331708\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.05946233704162504\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.019490863990655492\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.010022843360689298\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.0003168031741158774\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 5.5091076395742724e-05\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 3.7871365144603454e-05\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 2.203725457052753e-06\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 6.196556751010036e-08\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 1.0538655795207974e-08\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 4.0810037000174624e-09\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 4.893162686496804e-13\n",
      "Miami Marlins\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2017.\n",
    "print (\"model_100----------------------------------------\")\n",
    "predict_the_winner(model_100, 2017, team_data, X_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_50----------------------------------------\n",
      "WS Probability = 0.9999458756548997\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.9989956506131888\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.9805611254024863\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.9599856218698107\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.9499002312201494\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.924390263390398\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.9167404244430902\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.890906760960234\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.8526350794733162\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.738125696779178\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.6398622562267948\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.4640262703499726\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.37688014296347727\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.3109300033432931\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.21837653319202155\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.2128897073820588\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.16520717717716485\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.15202655430923942\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.08386120427479006\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.06982369805279816\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.0384104328633419\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.03468810949117554\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.028089297967679606\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.019280782065873192\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.010814529971730349\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.0015643996826382978\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.0013263327332501953\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.0007387495006742654\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.0004487798527760502\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.00015792358476405087\n",
      "Chicago White Sox\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_50----------------------------------------\")\n",
    "predict_the_winner(model_50, 2017, team_data, X_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_25----------------------------------------\n",
      "WS Probability = 0.9998796941538302\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.9671919230640552\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.9608950640542029\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.9583152505871078\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.8251318303251219\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.8206102841601355\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.803729220607319\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.7936490020549267\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.6644508790365156\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.6551990301786715\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.5593731866551522\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.5525032372438307\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.387358463097562\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.35020975280533856\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.31839411059667944\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.12296688191915638\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.079341804595618\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.05574799516200801\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.016882875086465382\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.015942009325790638\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.010011267030103407\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.002055402372730862\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.0019277414409719898\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.0015926681366199265\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.0011433527133075045\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.0009675480552438549\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.0008913672077953508\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.0008370977285045342\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 5.8877138497880664e-05\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 2.953990018297079e-05\n",
      "Baltimore Orioles\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_25----------------------------------------\")\n",
    "predict_the_winner(model_25, 2017, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction for 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_100----------------------------------------\n",
      "WS Probability = 0.9999999998584037\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.9999999969415321\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.9999996089117351\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.9999675730777194\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.9998210695073947\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.9993820518236723\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.9993759841606927\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.9992579643904091\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.9960542762319331\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.9954804290878182\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.9873290631075351\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.9768067811130619\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.7596006521488354\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.7340899087859907\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.7141126029881957\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.6095752681612683\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.4746101831045438\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.14437510309603768\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.04961122064779092\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.041106003372081215\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.020541094244072005\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.009924504900787433\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.009808994707665282\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.008941755239120584\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.0037929426674377198\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.0007054696868990147\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 2.1382687914055065e-05\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 2.4283838828197764e-07\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 7.825169451603819e-13\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 1.800989000087963e-14\n",
      "Boston Red Sox\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2016.\n",
    "print (\"model_100----------------------------------------\")\n",
    "predict_the_winner(model_100, 2016, team_data, X_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_50----------------------------------------\n",
      "WS Probability = 0.9999929154747303\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.9945561617822243\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.98847307805359\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.987906484611737\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.9715602711150808\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.8713293185014833\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.8409713538851562\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.744085461364684\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.527138089823609\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.5046890875920984\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.4857919923818349\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.48210200840012135\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.22008811250756527\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.20422090655835579\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.16401053287129386\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.1508596413172163\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.0763017882871379\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.048615447981524056\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.048185253008041946\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.04725901455820024\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.040118527460613465\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.0196465657761579\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.015971783173871913\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.01498472208513316\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.012897279539495134\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.011550268165600569\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.009168342620821321\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.007353788559720779\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.0016350520916323596\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.0009333105763575314\n",
      "Chicago White Sox\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_50----------------------------------------\")\n",
    "predict_the_winner(model_50, 2016, team_data, X_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_25----------------------------------------\n",
      "WS Probability = 0.999979568965724\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.9952757645040042\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.9934884015233895\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.9421885096356508\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.921166544205374\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.9124871693422674\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.8947348944871364\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.8070546001677497\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.7975560477318313\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.6416985293669119\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.4193102673625983\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.22944240207341215\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.1596342596334687\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.031724018543375525\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.02655154592891983\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.026278666166044923\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.022589254663456806\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.01486395031584546\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.014581058653800733\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.010506964913407479\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.0063618058255173\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.0051860853187703825\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.005057082882039585\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.0034476649599201473\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.002479632783057107\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.0021590778316869816\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.0020132154057453727\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.0005759977434529521\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.00013246816505034918\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 3.9430114102708585e-05\n",
      "Chicago White Sox\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "print (\"model_25----------------------------------------\")\n",
    "predict_the_winner(model_25, 2016, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP4: Grid Search Model--SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_svc(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -X_test = scaled X test data.\n",
    "    -y_train = y train data.\n",
    "    -y_test = y test data.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -classification report (has F1 score, precision and recall).\n",
    "    -grid = saved model for prediction. \n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -the scaled and split data is put through a grid search with svc.\n",
    "    -the model is trained.\n",
    "    -a prediction is made.\n",
    "    -print out the classification report and give the model.\n",
    "    '''\n",
    "    \n",
    "    # set up svc model.\n",
    "    model = SVC(probability=True)\n",
    "\n",
    "    # create gridsearch estimator.\n",
    "    param_grid = {\"C\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "                  \"gamma\": [\"auto\", \"scale\"],\n",
    "                 \"kernel\": [\"poly\"]}\n",
    "    grid = GridSearchCV(model, param_grid, verbose=3)\n",
    "\n",
    "    # fit the model.\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # predict.\n",
    "    prediction = grid.predict(X_test)\n",
    "    \n",
    "    # print out the basic information about the grid search.\n",
    "    print (grid.best_params_)\n",
    "    print (grid.best_score_)\n",
    "    print (grid.best_estimator_)\n",
    "    \n",
    "    grid = grid.best_estimator_\n",
    "    predictions = grid.predict(X_test)\n",
    "    print (classification_report(y_test, prediction, target_names=[\"0\", \"1\"]))\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n",
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.5074106364428945, total=   1.6s\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.5069808027923212, total=   1.6s\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.5074235807860262, total=   1.6s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.5074106364428945, total=   1.6s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.5069808027923212, total=   1.6s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.5074235807860262, total=   1.6s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.5108979947689625, total=   1.6s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.5069808027923212, total=   1.6s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.5065502183406113, total=   1.5s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.5074106364428945, total=   1.5s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.5069808027923212, total=   1.6s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.5065502183406113, total=   1.6s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.7244986922406277, total=   1.5s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.7286212914485166, total=   1.5s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.6925764192139738, total=   1.5s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.7210113339145597, total=   1.7s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.7277486910994765, total=   1.7s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.6934497816593886, total=   1.6s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.7802964254577158, total=   1.4s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.7757417102966842, total=   1.4s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.7842794759825328, total=   1.3s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.7829119442022667, total=   1.3s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.7731239092495636, total=   1.4s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.777292576419214, total=   1.3s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.8125544899738448, total=   1.1s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.8464223385689355, total=   1.1s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.8646288209606987, total=   1.1s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8116826503923278, total=   1.2s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8472949389179756, total=   1.2s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8646288209606987, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   49.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.8411867364746946\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86       607\n",
      "           1       0.83      0.87      0.85       540\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1147\n",
      "   macro avg       0.85      0.85      0.85      1147\n",
      "weighted avg       0.85      0.85      0.85      1147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for 1 part 0 to 1 part 1\n",
    "model_100 = grid_search_svc(X_train_100, X_test_100, y_train_100, y_test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n",
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.6705069124423964, total=   0.7s\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.671280276816609, total=   0.6s\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.6709006928406467, total=   0.6s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.6705069124423964, total=   0.6s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.671280276816609, total=   0.6s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.6709006928406467, total=   0.6s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.6705069124423964, total=   0.6s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.671280276816609, total=   0.6s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.6709006928406467, total=   0.6s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.6705069124423964, total=   0.6s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.671280276816609, total=   0.7s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.6709006928406467, total=   0.6s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.6693548387096774, total=   0.7s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.6747404844290658, total=   0.6s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.6766743648960739, total=   0.7s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.6705069124423964, total=   0.7s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.6793540945790081, total=   0.7s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.6766743648960739, total=   0.6s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.7200460829493087, total=   0.6s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.7312572087658593, total=   0.6s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.7136258660508084, total=   0.6s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.7200460829493087, total=   0.7s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.7289504036908881, total=   0.6s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.7136258660508084, total=   0.6s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.7972350230414746, total=   0.6s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.8085351787773933, total=   0.6s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.7863741339491916, total=   0.6s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.7972350230414746, total=   0.6s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8085351787773933, total=   0.6s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.7863741339491916, total=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.7973856209150327\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88       606\n",
      "           1       0.85      0.51      0.64       261\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       867\n",
      "   macro avg       0.83      0.73      0.76       867\n",
      "weighted avg       0.83      0.82      0.81       867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for 1 part 0\\ to 0.5 part 1\n",
    "model_50 = grid_search_svc(X_train_50, X_test_50, y_train_50, y_test_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n",
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.0001, gamma=auto, kernel=poly ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.0001, gamma=auto, kernel=poly, score=0.8126721763085399, total=   0.3s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.0001, gamma=scale, kernel=poly ..............................\n",
      "[CV]  C=0.0001, gamma=scale, kernel=poly, score=0.8126721763085399, total=   0.3s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.001, gamma=auto, kernel=poly ................................\n",
      "[CV]  C=0.001, gamma=auto, kernel=poly, score=0.8126721763085399, total=   0.3s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.001, gamma=scale, kernel=poly ...............................\n",
      "[CV]  C=0.001, gamma=scale, kernel=poly, score=0.8126721763085399, total=   0.3s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.01, gamma=auto, kernel=poly .................................\n",
      "[CV]  C=0.01, gamma=auto, kernel=poly, score=0.8126721763085399, total=   0.3s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.8118131868131868, total=   0.3s\n",
      "[CV] C=0.01, gamma=scale, kernel=poly ................................\n",
      "[CV]  C=0.01, gamma=scale, kernel=poly, score=0.8126721763085399, total=   0.3s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.8214285714285714, total=   0.3s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.8090659340659341, total=   0.3s\n",
      "[CV] C=0.1, gamma=auto, kernel=poly ..................................\n",
      "[CV]  C=0.1, gamma=auto, kernel=poly, score=0.8168044077134986, total=   0.3s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.8214285714285714, total=   0.3s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.8145604395604396, total=   0.3s\n",
      "[CV] C=0.1, gamma=scale, kernel=poly .................................\n",
      "[CV]  C=0.1, gamma=scale, kernel=poly, score=0.8168044077134986, total=   0.3s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.8557692307692307, total=   0.3s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.853021978021978, total=   0.3s\n",
      "[CV] C=1, gamma=auto, kernel=poly ....................................\n",
      "[CV]  C=1, gamma=auto, kernel=poly, score=0.8539944903581267, total=   0.3s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8557692307692307, total=   0.3s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8543956043956044, total=   0.3s\n",
      "[CV] C=1, gamma=scale, kernel=poly ...................................\n",
      "[CV]  C=1, gamma=scale, kernel=poly, score=0.8539944903581267, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.8547204399633364\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91       579\n",
      "           1       0.77      0.36      0.49       149\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       728\n",
      "   macro avg       0.81      0.66      0.70       728\n",
      "weighted avg       0.84      0.85      0.82       728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for 1 part 0 to 0.25 part 1\n",
    "model_25 = grid_search_svc(X_train_25, X_test_25, y_train_25, y_test_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh.  That's pretty good.  Try out model_100 and model_50 with the 2016-2018 stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP5: Predict 2016-2018 winners with SVC Grid Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.9672681274154478\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.8380433619258659\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.8258653281915737\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.7675545468923061\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.6932602636988303\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.672279482445197\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.45122816682086053\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.42069818004077575\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.4010662014721142\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.3910822495608485\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.3731939146907646\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.33753143668217245\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.2771476589489649\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.26532127248186493\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.2388098303702007\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.23490797877407696\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.2248918101826335\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.22401599906395436\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.21362386001168573\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.20744468747772654\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.18007429572461245\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.1734867161564972\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.1284358342923874\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.09365751718249105\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.0412498492233191\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.03178818190990383\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.021477020438479513\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.019019982148364558\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.01782643365181948\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.0023048502971501077\n",
      "Seattle Mariners\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2018.\n",
    "predict_the_winner(model_100, 2018, team_data, X_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.987296710839614\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.9790525570344367\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.8677110306372905\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.7493516063931069\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.6524807333566126\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.5820173774748483\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.46969655290930373\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.44991635658540463\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.41668870356349386\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.39657968858920767\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.35153186028985756\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.3395206004839719\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.31073039818095005\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.30850731192920167\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.28574713719617734\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.2819991667166262\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.21218775605680604\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.19636899998566903\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.1825727596583458\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.1415152140660416\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.13980239332817931\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.1326901826458374\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.08274831831334788\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.07796324662274846\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.07700754651912639\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.050449043688136574\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.03019922923922384\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.027369523571342185\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.02470827010995699\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.021936311169846193\n",
      "Los Angeles Dodgers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2017.\n",
    "predict_the_winner(model_100, 2017, team_data, X_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.9999999765896943\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.999987049005604\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.9304841793301912\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.8444112198386886\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.8163435005323842\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.7555108051749393\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.7507357563633643\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.6951046687807705\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.6481039549509179\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.5679446431842795\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.5\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.4303512598882254\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.41928831511295755\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.4135124477888461\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.3028548940673995\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.27486919674029914\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.23654494172749513\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.22473638590922493\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.202738868946679\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.19024852032891415\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.17096968896309253\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.13058560560044097\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.12314343704207843\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.10451202721472226\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.09503314471384945\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.04145473449230714\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.03132881793387673\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.025837704666353774\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.014506363914938349\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.004877491237705513\n",
      "San Francisco Giants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2016\n",
    "predict_the_winner(model_100, 2016, team_data, X_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.7975398553719102\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.5901846721034164\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.42462875817217394\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.40642007030055194\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.34498810153828724\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.2961954108142491\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.2465596572981947\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.22671522998117466\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.20776475856396684\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.2011144702186935\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.19396757824854624\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.19062123910289838\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.17881621366810954\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.17242754297577717\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.16914282969381333\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.1671686549167636\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.16613444783593648\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.14381910187915484\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.14077951902771127\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.13307142452901113\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.11699364417856416\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.11620383943734387\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.11210323176484055\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.10439586094304375\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.10092963773714217\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.07524728426138669\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.07189822121364302\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.019531564597775268\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.0065515472889585745\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.002648907253336193\n",
      "Los Angeles Dodgers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2018\n",
    "predict_the_winner(model_50, 2018, team_data, X_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.8427022432788881\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.4223987827727567\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.2907878847271067\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.2726538261651381\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.23105784259359113\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.21423692354884888\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.2073463446136215\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.2065411791686153\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.20559789645788953\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.19838975200473422\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.1975014490238672\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.19490385538168722\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.18596410699731128\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.18080759644980302\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.18041784734460561\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.1718268071755939\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.1613541096818689\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.15017342546518264\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.13872792898756292\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.13850696695373235\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.1358168138032897\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.1319067010473457\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.13002061811377894\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.08547905034193128\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.08348935167219805\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.08230398748165679\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.053768013075451496\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.04131868588900226\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.03971463391578483\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.03811380983193684\n",
      "Texas Rangers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2017\n",
    "predict_the_winner(model_50, 2017, team_data, X_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.9602257526759964\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.5240449691019795\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.49055231351691386\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.46259247926200153\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.44035753960036855\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.37914483016449263\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.27661027653619413\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.2607423199708921\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.2515361365784386\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.24511220514230253\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.24087361977352922\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.2379157683438693\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.2345034840903647\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.2329766881265978\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.20887928950040346\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.1808913269904801\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.18048545742184008\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.17609411639731204\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.17210798876839115\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.17092233880606753\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.16982451890234565\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.15863136697443647\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.15007570040314755\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.1436318807752006\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.11180425811840461\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.1089827595877077\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.10230578993683703\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.07356072061924772\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.057524319528862396\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.0274059557975133\n",
      "Cincinnati Reds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2016\n",
    "predict_the_winner(model_50, 2016, team_data, X_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.465636808618478\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.4211690196282958\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.2441341491840563\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.23918937488688846\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.2299291347689194\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.20753199667805572\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.1865756072517449\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.15385950202031584\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.13286803823398288\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.13090510656047083\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.12772297055660692\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.11725720339526755\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.11275629933449453\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.11213069585108555\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.11105730301980869\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.11085040770421538\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.10986975837625425\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.09729933897071673\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.09466736046819337\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.08687159485838213\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.0838514928211377\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.078256079287066\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.07731028954748353\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.06872496700342583\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.06504820112457826\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.043763592763189404\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.028008801345186622\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.02780661579648249\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.02534445658817506\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.011318977229587393\n",
      "Seattle Mariners\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2018\n",
    "predict_the_winner(model_25, 2018, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.8649270133260044\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.1575466675148739\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.15070096228720414\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.1461229995634083\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.1334177444805497\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.11797252192970367\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.11689288203000858\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.11667238812643295\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.11197853742793157\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.10429583788931064\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.10390945774961756\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.10237419968395202\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.10028838242133929\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.0982347771740441\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.0956823015361471\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.09305358243727041\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.08994834321967701\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.08670743447570958\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.08513879853576489\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.08282224444889481\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.08250389825604298\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.07585128510229883\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.07396665908713151\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.07352223328007959\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.06467098529213988\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.04769411202475808\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.03495794841818569\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.030120172892233257\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.024847436201601358\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.016369642522988198\n",
      "San Diego Padres\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2017\n",
    "predict_the_winner(model_25, 2017, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.9999942753558461\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.44605610939929435\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.288731484876201\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.23316545065843852\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.21678508048837428\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.2154198753566374\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.20581963765732075\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.19595376679177975\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.19136591570110784\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.15049123064045772\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.1493669788539413\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.14299825810634004\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.12973857541668984\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.12790165169367937\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.11833723415696912\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.11334321434941935\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.11271537280775212\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.10638338858846726\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.10076755871251149\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.0991863954959426\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.09645794902064643\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.09478862679655607\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.0889196979729415\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.08342491269887357\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.06586864618888563\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.05432751160471674\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.052461379609059666\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.051326920780334115\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.050796521915543964\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.03163568927856309\n",
      "Cincinnati Reds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2016\n",
    "predict_the_winner(model_25, 2016, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS Probability = 0.465636808618478\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.4211690196282958\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.2441341491840563\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.23918937488688846\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.2299291347689194\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.20753199667805572\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.1865756072517449\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.15385950202031584\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.13286803823398288\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.13090510656047083\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.12772297055660692\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.11725720339526755\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.11275629933449453\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.11213069585108555\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.11105730301980869\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.11085040770421538\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.10986975837625425\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.09729933897071673\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.09466736046819337\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.08687159485838213\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.0838514928211377\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.078256079287066\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.07731028954748353\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.06872496700342583\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.06504820112457826\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.043763592763189404\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.028008801345186622\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.02780661579648249\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.02534445658817506\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.011318977229587393\n",
      "Seattle Mariners\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2019.\n",
    "predict_the_winner(model_25, 2019, team_data, X_train_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hm.  model_25 seems to be pretty good.  I mean, red sox is #2 for 2018, astros #1 for 2017, and the indians for 2016 (and they made it to the finals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
