{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: Try different models-- Part4.\n",
    "### PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP1: Read in dataset.  Remove data from 2016-2019.\n",
    "- data from 2016-2018 will be used to bs test the model.\n",
    "- data from 2019 will be used to predict the winners of the 2019 WS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St. Louis Cardinals</td>\n",
       "      <td>2019</td>\n",
       "      <td>1033</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>936</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>4</td>\n",
       "      <td>895</td>\n",
       "      <td>33</td>\n",
       "      <td>3896</td>\n",
       "      <td>56</td>\n",
       "      <td>1.29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona Diamondbacks</td>\n",
       "      <td>2019</td>\n",
       "      <td>1010</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>945</td>\n",
       "      <td>8538.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2846</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>7</td>\n",
       "      <td>925</td>\n",
       "      <td>24</td>\n",
       "      <td>4001</td>\n",
       "      <td>53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas City Royals</td>\n",
       "      <td>2019</td>\n",
       "      <td>990</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>...</td>\n",
       "      <td>543</td>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>24</td>\n",
       "      <td>4125</td>\n",
       "      <td>39</td>\n",
       "      <td>1.46</td>\n",
       "      <td>34</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2019</td>\n",
       "      <td>875</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8589.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2863</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>7</td>\n",
       "      <td>1074</td>\n",
       "      <td>27</td>\n",
       "      <td>3929</td>\n",
       "      <td>67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tampa Bay Rays</td>\n",
       "      <td>2019</td>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>963</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2920</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>26</td>\n",
       "      <td>3985</td>\n",
       "      <td>59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   team  year     A   DP   E   G2  GS2     INN  PB    PO  \\\n",
       "0   St. Louis Cardinals  2019  1033  114  43  104  936  8313.0   3  2771   \n",
       "1  Arizona Diamondbacks  2019  1010   83  45  105  945  8538.0   2  2846   \n",
       "2    Kansas City Royals  2019   990  105  45  106  954  8421.0   6  2807   \n",
       "3        Houston Astros  2019   875   54  50  106  954  8589.0   6  2863   \n",
       "4        Tampa Bay Rays  2019   975   92  53  107  963  8760.0  11  2920   \n",
       "\n",
       "    ...      R1  SHO   SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   ...     456    4   895  33  3896  56  1.29  21  0.538        0  \n",
       "1   ...     472    7   925  24  4001  53  1.28  35  0.505        0  \n",
       "2   ...     543    5   816  24  4125  39  1.46  34  0.368        0  \n",
       "3   ...     432    7  1074  27  3929  67  1.14  31  0.632        0  \n",
       "4   ...     409    6  1037  26  3985  59  1.16  40  0.551        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data.\n",
    "team_data = pd.read_csv(\"../../Resources/clean_data_1905.csv\")\n",
    "del team_data[\"Unnamed: 0\"]\n",
    "team_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>2015</td>\n",
       "      <td>1639</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4381</td>\n",
       "      <td>...</td>\n",
       "      <td>631</td>\n",
       "      <td>11</td>\n",
       "      <td>1309</td>\n",
       "      <td>43</td>\n",
       "      <td>6048</td>\n",
       "      <td>87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>1425</td>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13137.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4379</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>46</td>\n",
       "      <td>6036</td>\n",
       "      <td>95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>47</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2015</td>\n",
       "      <td>1599</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4404</td>\n",
       "      <td>...</td>\n",
       "      <td>701</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>44</td>\n",
       "      <td>6180</td>\n",
       "      <td>84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>98</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>2015</td>\n",
       "      <td>1537</td>\n",
       "      <td>148</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>1449</td>\n",
       "      <td>12852.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>721</td>\n",
       "      <td>8</td>\n",
       "      <td>1232</td>\n",
       "      <td>47</td>\n",
       "      <td>6048</td>\n",
       "      <td>86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>2015</td>\n",
       "      <td>1427</td>\n",
       "      <td>139</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>12957.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4319</td>\n",
       "      <td>...</td>\n",
       "      <td>694</td>\n",
       "      <td>5</td>\n",
       "      <td>1362</td>\n",
       "      <td>43</td>\n",
       "      <td>6073</td>\n",
       "      <td>93</td>\n",
       "      <td>1.27</td>\n",
       "      <td>52</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     team  year     A   DP   E   G2   GS2      INN  PB    PO  \\\n",
       "120  San Francisco Giants  2015  1639  136  72  162  1458  13143.0   6  4381   \n",
       "121  Washington Nationals  2015  1425  142  73  162  1458  13137.0  17  4379   \n",
       "122        Houston Astros  2015  1599  135  77  162  1458  13212.0  18  4404   \n",
       "123        Detroit Tigers  2015  1537  148  75  161  1449  12852.0   5  4284   \n",
       "124        Boston Red Sox  2015  1427  139  75  162  1458  12957.0  37  4319   \n",
       "\n",
       "      ...      R1  SHO   SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "120   ...     631   11  1309  43  6048  87  1.21  40  0.537        0  \n",
       "121   ...     612   12  1476  46  6036  95  1.19  47  0.586        0  \n",
       "122   ...     701    8  1396  44  6180  84  1.29  98  0.519        0  \n",
       "123   ...     721    8  1232  47  6048  86  1.32  44  0.534        0  \n",
       "124   ...     694    5  1362  43  6073  93  1.27  52  0.574        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove data from 2016 through 2019.\n",
    "team_data_new = team_data.loc[team_data[\"year\"] < 2016]\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2344,)\n",
      "(2344, 52)\n",
      "['A', 'DP', 'E', 'G2', 'GS2', 'INN', 'PB', 'PO', 'TC', '2B', '3B', 'AB', 'AO', 'BB', 'G', 'H', 'HBP', 'HR', 'NP_x', 'OBP', 'OPS_x', 'PA', 'R', 'RBI', 'SAC', 'SB', 'SLG', 'TB', 'XBH', 'BB1', 'BK', 'CG', 'ER', 'ERA', 'G1', 'GF', 'GS', 'H1', 'HB', 'HR1', 'IP', 'L', 'OBP1', 'R1', 'SHO', 'SO1', 'SV', 'TBF', 'W', 'WHIP', 'WP', 'WPCT']\n"
     ]
    }
   ],
   "source": [
    "target = team_data_new[\"winners\"]\n",
    "features = team_data_new.drop({\"team\", \"year\", \"winners\"}, axis=1)\n",
    "feature_columns = list(features.columns)\n",
    "print (target.shape)\n",
    "print (features.shape)\n",
    "print (feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP2: Upsample and scale data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Francisco Giants</td>\n",
       "      <td>2015</td>\n",
       "      <td>1639</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13143.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4381</td>\n",
       "      <td>...</td>\n",
       "      <td>631</td>\n",
       "      <td>11</td>\n",
       "      <td>1309</td>\n",
       "      <td>43</td>\n",
       "      <td>6048</td>\n",
       "      <td>87</td>\n",
       "      <td>1.21</td>\n",
       "      <td>40</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>2015</td>\n",
       "      <td>1425</td>\n",
       "      <td>142</td>\n",
       "      <td>73</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13137.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4379</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>12</td>\n",
       "      <td>1476</td>\n",
       "      <td>46</td>\n",
       "      <td>6036</td>\n",
       "      <td>95</td>\n",
       "      <td>1.19</td>\n",
       "      <td>47</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston Astros</td>\n",
       "      <td>2015</td>\n",
       "      <td>1599</td>\n",
       "      <td>135</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>13212.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4404</td>\n",
       "      <td>...</td>\n",
       "      <td>701</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>44</td>\n",
       "      <td>6180</td>\n",
       "      <td>84</td>\n",
       "      <td>1.29</td>\n",
       "      <td>98</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Detroit Tigers</td>\n",
       "      <td>2015</td>\n",
       "      <td>1537</td>\n",
       "      <td>148</td>\n",
       "      <td>75</td>\n",
       "      <td>161</td>\n",
       "      <td>1449</td>\n",
       "      <td>12852.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4284</td>\n",
       "      <td>...</td>\n",
       "      <td>721</td>\n",
       "      <td>8</td>\n",
       "      <td>1232</td>\n",
       "      <td>47</td>\n",
       "      <td>6048</td>\n",
       "      <td>86</td>\n",
       "      <td>1.32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston Red Sox</td>\n",
       "      <td>2015</td>\n",
       "      <td>1427</td>\n",
       "      <td>139</td>\n",
       "      <td>75</td>\n",
       "      <td>162</td>\n",
       "      <td>1458</td>\n",
       "      <td>12957.0</td>\n",
       "      <td>37</td>\n",
       "      <td>4319</td>\n",
       "      <td>...</td>\n",
       "      <td>694</td>\n",
       "      <td>5</td>\n",
       "      <td>1362</td>\n",
       "      <td>43</td>\n",
       "      <td>6073</td>\n",
       "      <td>93</td>\n",
       "      <td>1.27</td>\n",
       "      <td>52</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   team  year     A   DP   E   G2   GS2      INN  PB    PO  \\\n",
       "0  San Francisco Giants  2015  1639  136  72  162  1458  13143.0   6  4381   \n",
       "1  Washington Nationals  2015  1425  142  73  162  1458  13137.0  17  4379   \n",
       "2        Houston Astros  2015  1599  135  77  162  1458  13212.0  18  4404   \n",
       "3        Detroit Tigers  2015  1537  148  75  161  1449  12852.0   5  4284   \n",
       "4        Boston Red Sox  2015  1427  139  75  162  1458  12957.0  37  4319   \n",
       "\n",
       "    ...      R1  SHO   SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   ...     631   11  1309  43  6048  87  1.21  40  0.537        0  \n",
       "1   ...     612   12  1476  46  6036  95  1.19  47  0.586        0  \n",
       "2   ...     701    8  1396  44  6180  84  1.29  98  0.519        0  \n",
       "3   ...     721    8  1232  47  6048  86  1.32  44  0.534        0  \n",
       "4   ...     694    5  1362  43  6073  93  1.27  52  0.574        0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset the index.\n",
    "team_data_new = team_data_new.reset_index().drop({\"index\"}, axis=1)\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>G2</th>\n",
       "      <th>GS2</th>\n",
       "      <th>INN</th>\n",
       "      <th>PB</th>\n",
       "      <th>PO</th>\n",
       "      <th>TC</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>R1</th>\n",
       "      <th>SHO</th>\n",
       "      <th>SO1</th>\n",
       "      <th>SV</th>\n",
       "      <th>TBF</th>\n",
       "      <th>W</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>WPCT</th>\n",
       "      <th>winners</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1033</td>\n",
       "      <td>114</td>\n",
       "      <td>43</td>\n",
       "      <td>104</td>\n",
       "      <td>936</td>\n",
       "      <td>8313.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2771</td>\n",
       "      <td>3847</td>\n",
       "      <td>157</td>\n",
       "      <td>...</td>\n",
       "      <td>456</td>\n",
       "      <td>4</td>\n",
       "      <td>895</td>\n",
       "      <td>33</td>\n",
       "      <td>3896</td>\n",
       "      <td>56</td>\n",
       "      <td>1.29</td>\n",
       "      <td>21</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>83</td>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>945</td>\n",
       "      <td>8538.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2846</td>\n",
       "      <td>3901</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>472</td>\n",
       "      <td>7</td>\n",
       "      <td>925</td>\n",
       "      <td>24</td>\n",
       "      <td>4001</td>\n",
       "      <td>53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>35</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>105</td>\n",
       "      <td>45</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8421.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>3842</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>543</td>\n",
       "      <td>5</td>\n",
       "      <td>816</td>\n",
       "      <td>24</td>\n",
       "      <td>4125</td>\n",
       "      <td>39</td>\n",
       "      <td>1.46</td>\n",
       "      <td>34</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>875</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>106</td>\n",
       "      <td>954</td>\n",
       "      <td>8589.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2863</td>\n",
       "      <td>3788</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>7</td>\n",
       "      <td>1074</td>\n",
       "      <td>27</td>\n",
       "      <td>3929</td>\n",
       "      <td>67</td>\n",
       "      <td>1.14</td>\n",
       "      <td>31</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>975</td>\n",
       "      <td>92</td>\n",
       "      <td>53</td>\n",
       "      <td>107</td>\n",
       "      <td>963</td>\n",
       "      <td>8760.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2920</td>\n",
       "      <td>3948</td>\n",
       "      <td>195</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>6</td>\n",
       "      <td>1037</td>\n",
       "      <td>26</td>\n",
       "      <td>3985</td>\n",
       "      <td>59</td>\n",
       "      <td>1.16</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   DP   E   G2  GS2     INN  PB    PO    TC   2B   ...      R1  SHO  \\\n",
       "0  1033  114  43  104  936  8313.0   3  2771  3847  157   ...     456    4   \n",
       "1  1010   83  45  105  945  8538.0   2  2846  3901  203   ...     472    7   \n",
       "2   990  105  45  106  954  8421.0   6  2807  3842  185   ...     543    5   \n",
       "3   875   54  50  106  954  8589.0   6  2863  3788  200   ...     432    7   \n",
       "4   975   92  53  107  963  8760.0  11  2920  3948  195   ...     409    6   \n",
       "\n",
       "    SO1  SV   TBF   W  WHIP  WP   WPCT  winners  \n",
       "0   895  33  3896  56  1.29  21  0.538        0  \n",
       "1   925  24  4001  53  1.28  35  0.505        0  \n",
       "2   816  24  4125  39  1.46  34  0.368        0  \n",
       "3  1074  27  3929  67  1.14  31  0.632        0  \n",
       "4  1037  26  3985  59  1.16  40  0.551        0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove team and year.\n",
    "feature_columns_new = feature_columns + [\"winners\"]\n",
    "team_data_new = team_data[feature_columns_new]\n",
    "team_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample for a more balanced dataset.\n",
    "def upsample(dataset, no_samples, no_components):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -dataset = dataset without team names and year.\n",
    "    -n_samples = number of minority_unsampled.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -X_train_scaled = scaled X train data.\n",
    "    -X_test_scaled = scaled X test data.\n",
    "    -y_train = y train data\n",
    "    -y_test = y test data\n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -dataset is taken in and split into minority and majority classes.\n",
    "    -dataset is then upsampled for the mainority class\n",
    "    -split the data into features and targets\n",
    "    -split data into train and test sets\n",
    "    -train and test sets were are scaled.\n",
    "    '''\n",
    "    \n",
    "    # separate majority and minority classes.\n",
    "    df_majority = dataset.loc[dataset[\"winners\"] == 0]\n",
    "    df_minority = dataset.loc[dataset[\"winners\"] == 1]\n",
    "\n",
    "    # upsample minority class.\n",
    "    df_minority_unsampled = resample(df_minority,\n",
    "                                    replace=True,\n",
    "                                    n_samples=no_samples,\n",
    "                                    random_state=123)\n",
    "\n",
    "    # combine majority class with upsampled minority class.\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_unsampled])\n",
    "\n",
    "    # separate features and target.\n",
    "    y = df_upsampled[\"winners\"]\n",
    "    X = df_upsampled[feature_columns]\n",
    "    \n",
    "    # split into train and test sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "    # scale.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    \n",
    "    # PCA.\n",
    "    pca = PCA(n_components=no_components)\n",
    "    X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "    X_test_scaled = pca.fit_transform(X_test_scaled)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Do three different upsamplings and three different pca conditions.\n",
    "X_train_100_10, X_test_100_10, y_train_100_10, y_test_100_10 = upsample(team_data_new, 2234, 10)\n",
    "X_train_100_5, X_test_100_5, y_train_100_5, y_test_100_5 = upsample(team_data_new, 2234, 5)\n",
    "X_train_100_2, X_test_100_2, y_train_100_2, y_test_100_2 = upsample(team_data_new, 2234, 2)\n",
    "\n",
    "X_train_50_10, X_test_50_10, y_train_50_10, y_test_50_10 = upsample(team_data_new, 1117, 10)\n",
    "X_train_50_5, X_test_50_5, y_train_50_5, y_test_50_5 = upsample(team_data_new, 1117, 5)\n",
    "X_train_50_2, X_test_50_2, y_train_50_2, y_test_50_2 = upsample(team_data_new, 1117, 2)\n",
    "\n",
    "X_train_25_10, X_test_25_10, y_train_25_10, y_test_25_10 = upsample(team_data_new, 559, 10)\n",
    "X_train_25_5, X_test_25_5, y_train_25_5, y_test_25_5 = upsample(team_data_new, 559, 5)\n",
    "X_train_25_2, X_test_25_2, y_train_25_2, y_test_25_2 = upsample(team_data_new, 559, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train, X_test, y_train, y_test):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -X_test = scaled X test data.\n",
    "    -y_train = y train data.\n",
    "    -y_test = y test data.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -classification report (has F1 score, precision and recall).\n",
    "    -grid = saved model for prediction. \n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -the scaled and split data is put through a grid search with logistic.\n",
    "    -the model is trained.\n",
    "    -a prediction is made.\n",
    "    -print out the classification report and give the model.\n",
    "    '''\n",
    "    \n",
    "    # fit the model.\n",
    "    model = LogisticRegression(solver=\"lbfgs\", max_iter= 2000)\n",
    "\n",
    "    # fit the model.\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict.\n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    print (classification_report(y_test, prediction, target_names=[\"0\", \"1\"]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64       607\n",
      "           1       0.59      0.60      0.60       540\n",
      "\n",
      "   micro avg       0.62      0.62      0.62      1147\n",
      "   macro avg       0.62      0.62      0.62      1147\n",
      "weighted avg       0.62      0.62      0.62      1147\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100_10 = logistic(X_train_100_10, X_test_100_10, y_train_100_10, y_test_100_10)\n",
    "model_100_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63       607\n",
      "           1       0.59      0.59      0.59       540\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      1147\n",
      "   macro avg       0.61      0.61      0.61      1147\n",
      "weighted avg       0.61      0.61      0.61      1147\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100_5 = logistic(X_train_100_5, X_test_100_5, y_train_100_5, y_test_100_5)\n",
    "model_100_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.58       607\n",
      "           1       0.55      0.62      0.58       540\n",
      "\n",
      "   micro avg       0.58      0.58      0.58      1147\n",
      "   macro avg       0.58      0.58      0.58      1147\n",
      "weighted avg       0.58      0.58      0.58      1147\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_100_2 = logistic(X_train_100_2, X_test_100_2, y_train_100_2, y_test_100_2)\n",
    "model_100_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       606\n",
      "           1       0.63      0.48      0.54       261\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       867\n",
      "   macro avg       0.71      0.68      0.69       867\n",
      "weighted avg       0.75      0.76      0.75       867\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50_10 = logistic(X_train_50_10, X_test_50_10, y_train_50_10, y_test_50_10)\n",
    "model_50_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       606\n",
      "           1       0.64      0.46      0.54       261\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       867\n",
      "   macro avg       0.72      0.67      0.69       867\n",
      "weighted avg       0.75      0.76      0.75       867\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_50_5 = logistic(X_train_50_5, X_test_50_5, y_train_50_5, y_test_50_5)\n",
    "model_50_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87       579\n",
      "           1       0.30      0.10      0.15       149\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       728\n",
      "   macro avg       0.55      0.52      0.51       728\n",
      "weighted avg       0.70      0.77      0.72       728\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25_10 = logistic(X_train_25_10, X_test_25_10, y_train_25_10, y_test_25_10)\n",
    "model_25_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87       579\n",
      "           1       0.30      0.09      0.14       149\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       728\n",
      "   macro avg       0.55      0.52      0.51       728\n",
      "weighted avg       0.70      0.77      0.72       728\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25_5 = logistic(X_train_25_5, X_test_25_5, y_train_25_5, y_test_25_5)\n",
    "model_25_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       579\n",
      "           1       0.00      0.00      0.00       149\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       728\n",
      "   macro avg       0.40      0.50      0.44       728\n",
      "weighted avg       0.63      0.80      0.70       728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=2000, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_25_2 = logistic(X_train_25_2, X_test_25_2, y_train_25_2, y_test_25_2)\n",
    "model_25_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model_100_10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_the_winner(model, year, team_data, X_train, no_components):\n",
    "    '''\n",
    "    INPUT: \n",
    "    -X_train = scaled X train data.\n",
    "    -model = the saved model.\n",
    "    -team_data = complete dataframe with all data.\n",
    "    -year = the year want to look at.\n",
    "    \n",
    "    OUTPUT:\n",
    "    -printed prediction.\n",
    "    \n",
    "    DESCRIPTION:\n",
    "    -data from year of interest is isolated.\n",
    "    -the data are scaled.\n",
    "    -the prediction is made.\n",
    "    -print out the resulting probability and the name of the team.\n",
    "    '''\n",
    "    \n",
    "    # grab the data.\n",
    "    team_data = team_data.loc[team_data[\"year\"] == year].reset_index()\n",
    "\n",
    "    # set features (no team, year, winners).\n",
    "    # set target (winners).\n",
    "    features = team_data[feature_columns]\n",
    "    \n",
    "    # scale.\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    features = scaler.fit_transform(features)\n",
    "    \n",
    "    # PCA.\n",
    "    pca = PCA(n_components=no_components)\n",
    "    X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "    features = pca.fit_transform(features)\n",
    "    \n",
    "    # fit the model.\n",
    "    probabilities = model.predict_proba(features)\n",
    "\n",
    "    # convert predictions to datafram.e\n",
    "    WS_predictions = pd.DataFrame(probabilities[:,1])\n",
    "\n",
    "    # Sort the DataFrame (descending)\n",
    "    WS_predictions = WS_predictions.sort_values(0, ascending=False)\n",
    "\n",
    "    WS_predictions['Probability'] = WS_predictions[0]\n",
    "\n",
    "    # Print 50 highest probability HoF inductees from still eligible players\n",
    "    for i, row in WS_predictions.head(50).iterrows():\n",
    "       prob = ' '.join(('WS Probability =', str(row['Probability'])))\n",
    "       print('')\n",
    "       print(prob)\n",
    "       print(team_data.iloc[i,1:27][\"team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WS Probability = 0.7594730963794484\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.7412167258534549\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.7388160037064428\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.7329006038263027\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.732739786098248\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.7240767149867644\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.7172268125793564\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.7033092609191622\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.6823478920325032\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.6578513682006203\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.6372086033690869\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.6091709189036797\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.5911946678817609\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.5575122343308863\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.5500955062393328\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.5121759648352695\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.3971052817579881\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.39299762911859343\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.3921588380252008\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.3753200133792733\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.3744667678377147\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.3536589781661895\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.3181042966700087\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.3005838085961805\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.27284609156263034\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.25469162831717906\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.2133506813127318\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.18296465654179134\n",
      "Chicago Cubs\n",
      "\n",
      "WS Probability = 0.15731771495127683\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.05548182279558234\n",
      "Colorado Rockies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2018.\n",
    "predict_the_winner(model_100_10, 2018, team_data, X_train_100_10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WS Probability = 0.8293918312617757\n",
      "Detroit Tigers\n",
      "\n",
      "WS Probability = 0.7601659198388782\n",
      "Chicago White Sox\n",
      "\n",
      "WS Probability = 0.7593835501117804\n",
      "Toronto Blue Jays\n",
      "\n",
      "WS Probability = 0.757785288499586\n",
      "Washington Nationals\n",
      "\n",
      "WS Probability = 0.7273757317314907\n",
      "Houston Astros\n",
      "\n",
      "WS Probability = 0.6783056623194058\n",
      "Tampa Bay Rays\n",
      "\n",
      "WS Probability = 0.6616772334017265\n",
      "New York Yankees\n",
      "\n",
      "WS Probability = 0.623906430020604\n",
      "Philadelphia Phillies\n",
      "\n",
      "WS Probability = 0.6180715231033606\n",
      "Pittsburgh Pirates\n",
      "\n",
      "WS Probability = 0.6136959371058007\n",
      "Los Angeles Angels\n",
      "\n",
      "WS Probability = 0.599407453466772\n",
      "Boston Red Sox\n",
      "\n",
      "WS Probability = 0.5521794109378517\n",
      "Colorado Rockies\n",
      "\n",
      "WS Probability = 0.5182340401161531\n",
      "Atlanta Braves\n",
      "\n",
      "WS Probability = 0.5087572448409674\n",
      "San Diego Padres\n",
      "\n",
      "WS Probability = 0.5013797461030631\n",
      "Kansas City Royals\n",
      "\n",
      "WS Probability = 0.49896801945784275\n",
      "Texas Rangers\n",
      "\n",
      "WS Probability = 0.49253183911682824\n",
      "Los Angeles Dodgers\n",
      "\n",
      "WS Probability = 0.47929613857098835\n",
      "Miami Marlins\n",
      "\n",
      "WS Probability = 0.47619665665622857\n",
      "Baltimore Orioles\n",
      "\n",
      "WS Probability = 0.441856484078257\n",
      "Milwaukee Brewers\n",
      "\n",
      "WS Probability = 0.4282088900857135\n",
      "Minnesota Twins\n",
      "\n",
      "WS Probability = 0.4048340636055375\n",
      "Cincinnati Reds\n",
      "\n",
      "WS Probability = 0.3681422741926885\n",
      "Seattle Mariners\n",
      "\n",
      "WS Probability = 0.30020325338272386\n",
      "Arizona Diamondbacks\n",
      "\n",
      "WS Probability = 0.2765644446776835\n",
      "Cleveland Indians\n",
      "\n",
      "WS Probability = 0.27058580528833626\n",
      "New York Mets\n",
      "\n",
      "WS Probability = 0.20589162934114413\n",
      "St. Louis Cardinals\n",
      "\n",
      "WS Probability = 0.17117808666746254\n",
      "Oakland Athletics\n",
      "\n",
      "WS Probability = 0.1519366657138245\n",
      "San Francisco Giants\n",
      "\n",
      "WS Probability = 0.043514199102778144\n",
      "Chicago Cubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Applications/anaconda3/envs/PythonData/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# predict for 2017.\n",
    "predict_the_winner(model_100_10, 2017, team_data, X_train_100_10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is not it.  The F1 scores are terrible and the bs test doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
